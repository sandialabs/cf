Phases:
  - Evidence
  - Assess
  - Aggregate
  - Stamp
  - Planning
Roles:
  - Customer
  - System Engineer
  - Analyst
  - Code Developer
  - Experimentalist
  - V&V Partner
Levels:
  Level 0:
    Code: 0
    Color: 255,0,0
  Level 1:
    Code: 1
    Color: 255,255,0
  Level 2:
    Code: 2
    Color: 255,192,0
  Level 3:
    Code: 3
    Color: 0,176,80
Elements:
  RGF: 
    Name: Representation and Geometric Fidelity
    Abbreviation: RGF
    Color: 0,142,116
    Levels: 
      Level 0 : 
        Code: 0
        Name: Level 0 
        Descriptors: 
          Descriptor: "Model has no major or minor features present. Model is mainly \"blobs\" or point masses or stick-figure models or a curve fit of data."
          Additional Info: "The current writing is centric to meshed geometries. The words are not applicable to more general representation resolution issues. This is a TBD issue. RGF1 speaks to the level of meshed geometric detail in the problem. Level 0 means that there is essentially no discernible level of meshed detail in the presented predictive capability. Conceptual representation of the simulated geometry may be interpreted as detailed cadcam representation of the physical geometry exists, even though this is neglected in the computational simulation capability. The word \"model\" means \"predictive computational simulation capability for the intended application.\" "
          Change(s) from previous level: "n/a"
          Brief description of evidence relevant to this level: "Evidence of \"blobs\" etc. is presented."
          Additional evidence from previous level: "n/a"
          Key Words/Phrases: "Model = finite element model"
      Level 1: 
        Code: 1
        Name: Level 1
        Descriptors: 
          Descriptor: "Relative to the actual system, the meshed model is a de-featured representation of it. Subject matter expertise may define this level of meshing and define the meaning of \"major features,\" relationship to \"actual system,\" etc."
          Additional Info: " \"Major feature\" must be defined in the context of the anticipated predictive application of the computational model.  \"Actual system\" must also be defined. (i.e. CadCam,  blueprints of customer drawing, or existing hardware ).  Fillets are omitted, components are \"blobs\" or point masses, minor features are absent "
          Change(s) from previous level: "Main differences between Level 0 and 1: 
1) Information is provided that the representation/geometry has meshed some of the major features not present in Level 0."
          Brief description of evidence relevant to this level: "Specification of \"relative to the actual system.\" Define \"major features\" and provide evidence of the problem components where representation/geometry features have, and have not, been meshed. "
          Additional evidence from previous level: "Definition of \"major features.\" Characterization of where major features of have been meshed. Characterization of where features have not been meshed."
          Key Words/Phrases: "de-featured might equal to components modeled as blobs; major features; actual system"
      Level 2: 
        Code: 2
        Name: Level 2
        Descriptors: 
          Descriptor: "Relative to the actual system, the model has most of the major features. Component geometries are accurate meshed, but most fillets are omitted, bolts and holes may or may not be included, etc.  Subject matter expertise may define this level of meshing and define the meaning of \"major features.\""
          Additional Info: "\"Major feature\" must be defined in the context of the anticipated predictive application of the computational model.\" Minor feature\" must be defined. \"Actual system\" must be defined. I assume this refers to the system as \"actually represented in a cadcam system\" (or blueprints of customer drawing or hunk of hardware sitting on a table or whatever) - but it must be clarified. I don't know what to say unless we just say: \" 'Actual system' means 'cadcam representation' for purposes of this discussion. Otherwise - definition of 'actual system' must be provided along with the 'major feature' meshing discussion.\""
          Change(s) from previous level: "Main differences between Level 1 and 2: 
1) \"Major features\" are defined. (2) Specification of what \"most\" means regarding major features. The word \"most\" implies that any major features NOT meshed are identified. 3) Information  provided that the representation/geometry has meshed most of the major features not present in Level 1. 
4) Identification of the minor features  included (i.e. fillets, holes, bolts, etc.)."
          Brief description of evidence relevant to this level: "(1) Evidence of the problem components where representation/geometry features have, and have not, been meshed. (2) The \"Major features\" included in the representation/geometry. (3) Evidence of the major feature meshing. (4) Meaning of \"most\" and evidence it is achieved."
          Additional evidence from previous level: "Meaning of \"most\" and evidence it is achieved."
          Key Words/Phrases: ""
      Level 3: 
        Code: 3
        Name: Level 3
        Descriptors: 
          Descriptor: "Model represents \"as built\" system including all \"major features\" and most \"minor features.\" \"All\" defined by the evaluation team. \"Most\" defined by the evaluation team."
          Additional Info: "\"Major feature\" MUST BE DEFINED in the context of the anticipated predictive application of the computational model. \" Minor feature\" must be defined. \"Actual system\" must be defined. "
          Change(s) from previous level: "Main differences between Level 2 and 3: 
1) ALL identified major features included
2) Most of the minor features are included (i.e. fillets, holes, bolts, cables, etc.)."
          Brief description of evidence relevant to this level: "(1) Evidence of the problem components where representation/geometry features have, and have not, been meshed. (2) That ALL \"major features\" are included in the representation/geometry. (3) Evidence that ALL major features are meshed. (4) That \"most\" minor features are included in representation/geometry and meshed. (5) Meaning of \"most\" and evidence it is achieved. Define major features\" and summarize the problem components where features have, and have not, been meshed. Explain the reasons (provide the evidence) that ALL of the major features have been meshed. Define \"minor features,\" and explain why those present were selected. Explain the reasons (provide the evidence) that MOST of the minor features are meshed. A peer review is performed."
          Additional evidence from previous level: "Explanation/evidence that ALL identified \"major features\" have been meshed. Definition of \"minor features.\" Explanation/evidence that \"most\" minor features of have been meshed. Characterization of where minor features have not been meshed."
          Key Words/Phrases: "\"As built system\""
    Subelements: 
  PMMF: 
    Name: Physics and Material Model Fidelity
    Abbreviation: PMMF
    Color: 108,179,18
    Levels: 
      Level 0: 
        Code: 0
        Name: Level 0
        Descriptors: 
          Descriptor: "No correlation of relevant material/physics models in the capability with the PIRT for the intended application is presented; alternative view - NO PIRT elements are present in the capability to be applied."
          Additional Info: "[This subelement is now redefined to measure the degree to which the capability mat/physics models are correlated with the mandatory PIRT.][note - emphasis on \"knobs\" implies calibration emphasis. Calibration = \"tuning the predictive capability to maximize agreement with a specified set of benchmarks, such as selected experimental data.\" An explanatory model provides a basis for understanding why it is in agreement with selected benchmarks. A  calibrated model is not explanatory in the absence of further information. Sometimes the term \"physics-based model\" is used to convey a sense of \"explanatory\" but the term \"explanatory\" has wider scope than \"physics-based\" and that is our preferred terminology. \"Explanatory\" also suggests that the domain where a model is \"calibrated\" can be significantly larger than the domain where it is \"explanatory.\"]"
          Change(s) from previous level: "n/a"
          Brief description of evidence relevant to this level: "None REQUIRED; alternative - documentation that no PIRT elements are in the capability"
          Additional evidence from previous level: "N/A"
          Key Words/Phrases: "PIRT = see V&V documentation; Correlated = logically and substantively linked to the PIRT and its underlying logic - all PIRT elements; other similar words - \"related,\" \"connected,\" \"derived from,\" etc."
      Level 1: 
        Code: 1
        Name: Level 1
        Descriptors: 
          Descriptor: "Some relevant material/physics models in the capability are correlated with the PIRT for the intended application"
          Additional Info: ""
          Change(s) from previous level: "Main differences between Level 0 and 1: 
1) Some PIRT mat/phys models are identified in the capability"
          Brief description of evidence relevant to this level: "Documentation of correlated models and logic underlying correlation claims"
          Additional evidence from previous level: "Documentation"
          Key Words/Phrases: "Some = less than or equal to 50% of the total PIRT-identified mat/physics models. Evaluation team judgment determines the \"total\" list, and therefore also determines what \"some\" means."
      Level 2: 
        Code: 2
        Name: Level 2
        Descriptors: 
          Descriptor: "Most relevant material/physics models in the capability are correlated with the PIRT for the intended application"
          Additional Info: ""
          Change(s) from previous level: "Main differences between Level 1 and 2: 
1) Most PIRT mat/phys models are identified in the capability"
          Brief description of evidence relevant to this level: "Documentation of correlated models and logic underlying correlation claims"
          Additional evidence from previous level: "No change"
          Key Words/Phrases: "Most =More than 50% of the total PIRT-identified mat/physics models. Evaluation team judgment  what \"most\" means."
      Level 3: 
        Code: 3
        Name: Level 3
        Descriptors: 
          Descriptor: "All relevant material/physics models in the capability are correlated with the PIRT for the intended application"
          Additional Info: ""
          Change(s) from previous level: "Main differences between Level 2 and 3: 
1) All relevant PIRT mat/phys models are identified in the capability"
          Brief description of evidence relevant to this level: "Documentation of correlated models and logic underlying correlation claims"
          Additional evidence from previous level: "No Change"
          Key Words/Phrases: "All = all relevant PIRT identified mat/physics models are represented in the capability. Evaluation team judgment - the total set of relevant mat/phys models from the PIRT."
    Subelements: 
  CVER: 
    Name: Code Verification
    Abbreviation: CVER
    Color: 255,160,51
    Levels: 
      Level 0: 
        Code: 0
        Name: Level 0
        Descriptors: 
          Descriptor: "No identified SQE process "
          Additional Info: "This element requires input from a capability developer."
          Change(s) from previous level: "n/a"
          Brief description of evidence relevant to this level: "n/a"
          Key Words/Phrases: ""
      Level 1: 
        Code: 1
        Name: Level 1
        Descriptors: 
          Descriptor: "Code capability is managed to identified SQE practices"
          Additional Info: ""
          Change(s) from previous level: "Main differences between Level 0 and 1: 
1) Documented SQE process"
          Brief description of evidence relevant to this level: "Documentation of the SQE process applied"
          Key Words/Phrases: "\"Managed\" = ASC IC management (for example); defined in SNL ASC SQE Guidance"
      Level 2: 
        Code: 2
        Name: Level 2
        Descriptors: 
          Descriptor: "Code capability is managed to identified SQE practices. SQE process is managed."
          Additional Info: ""
          Change(s) from previous level: "Main differences between Level 1 and 2: 
1) SQE process is managed
2)"
          Brief description of evidence relevant to this level: "1) Documentation of the SQE process applied. 2) Documentation of the SQE management practices."
          Key Words/Phrases: "\"SQE Process Management\" = as defined in the SNL ASC SQE Guidance"
      Level 3: 
        Code: 3
        Name: Level 3
        Descriptors: 
          Descriptor: "Code capability is managed to identified SQE practices. SQE process is managed and optimized."
          Additional Info: ""
          Change(s) from previous level: "Main differences between Level 2 and 3: 
1) SQE process is optimized
2) "
          Brief description of evidence relevant to this level: "1) Documentation of the SQE process applied. 2) Documentation of the SQE management practices. 3) Documentation supporting achievement of process optimization."
          Key Words/Phrases: "\"Optimized\" = as defined in the SNL ASC SQE Guidance"
    Subelements: 
  SVER: 
    Name: Solution Verification
    Abbreviation: SVER
    Color: 169,44,0
    Levels: 
      Level 0: 
        Code: 0
        Name: Level 0
        Descriptors: 
          Descriptor: "Errors due to mesh size not examined"
          Additional Info: "Level 0 = not acknowledgement or discussion of solution error."
          Change(s) from previous level: "n/a"
          Brief description of evidence relevant to this level: "n/a"
          Additional evidence from previous level: "n/a"
          Key Words/Phrases: ""
      Level 1: 
        Code: 1
        Name: Level 1
        Descriptors: 
          Descriptor: "Sensitivity, or robustness, of one or more computed quantities of interest (QoI) to mesh resolution and numerical solution parameters is  studied and presented. Quantification as a computational \"error\" is not required or expected. Conclusions may be qualitative."
          Additional Info: " \"Computational error\" = putting an error bar reflecting understanding/estimate of the computation error of the QoIs selected. This is Level 2."
          Change(s) from previous level: "Main differences between Level 0 and 1: 
1) Numerical \"sensitivity\" of one or more QoIs is analyzed and reported."
          Brief description of evidence relevant to this level: "1) Documentation of sensitivity analysis and conclusions."
          Additional evidence from previous level: "n/a"
          Key Words/Phrases: "\"Sensitivity\" = change in QoI to variation of mesh resolution and/or solution parameters. \"Robustness\" = lack of change of QoI to variation of mesh resolution and/or solution parameters."
      Level 2: 
        Code: 2
        Name: Level 2
        Descriptors: 
          Descriptor: "Computational errors, due to mesh resolution and choice of numerical solution parameters, in one or more QoIs are estimated, analyzed and reported. The computational errors are interpreted as error bars on the computed results for the chosen QoIs. The question \"What is the validity of these error estimates\" is answered."
          Additional Info: "The answer to the question of why the reported error estimate(s) is valid can be \"I don't know.\""
          Change(s) from previous level: "Main differences between Level 1 and 2: 
1) Computational errors are estimated for one or more QOIs
2) Validity of the numerical error estimates is considered"
          Brief description of evidence relevant to this level: "1) Documentation of error analysis and conclusions.
2) Documentation of the analysis and conclusions of the validity question."
          Additional evidence from previous level: "1) Documentation of error analysis and conclusions.
2) Documentation of the analysis and conclusions of the validity question."
          Key Words/Phrases: ""
      Level 3: 
        Code: 3
        Name: Level 3
        Descriptors: 
          Descriptor: "Computational errors, due to mesh resolution and choice of numerical solution parameters, for all QoIs of the intended application are estimated, analyzed and reported. The computational errors are interpreted as error bars on the computed results for the chosen QoIs. The question \"What is the validity of these error estimates\" is answered."
          Additional Info: "The answer to the question of why the reported error estimate(s) is valid can be \"I don't know.\""
          Change(s) from previous level: "Main differences between Level 2 and 3: 
1) Computational errors are estimated for all QOIs
2) Validity of the numerical error estimates is considered"
          Brief description of evidence relevant to this level: "1) Documentation of error analysis and conclusions.
2) Documentation of the analysis and conclusions of the validity question.
3) Documentation of the completeness of identified QoIs."
          Additional evidence from previous level: "Documentation of the completeness of identified QoIs."
          Key Words/Phrases: ""
    Subelements: 
  VAL: 
    Name: Validation
    Abbreviation: VAL
    Color: 125,13,124
    Levels: 
      Level 0: 
        Code: 0
        Name: Level 0
        Descriptors: 
          Descriptor: "No validation hierarchy is defined (presented, specified, identified, acknowledged, etc.)."
          Additional Info: "\"Validation Hierarchy\" is defined in Sandia V&V planning report. This level implies \"NO VALIDATION PLAN.\"  Inability to define a validation hierarchy means that there is no validation plan or PIRT, in all likelihood. This issue is probably a gatekeeper, since we are thinking that a PIRT is a necessary condition (at least) for a PCMM assessment."
          Change(s) from previous level: "n/a"
          Brief description of evidence relevant to this level: "Nothing. "
          Additional evidence from previous level: "n/a"
          Key Words/Phrases: "Validation hierarchy"
      Level 1: 
        Code: 1
        Name: Level 1
        Descriptors: 
          Descriptor: "One level (i.e. level refers to either material level, component level, subsystem level, etc.) of a complete validation hierarchy, or an incomplete validation hierarchy, is defined (etc.). "
          Additional Info: "Incomplete hierarchy can be specified by a PIRT but a validation plan is desired."
          Change(s) from previous level: "One level of a validation hierarchy is given. "
          Brief description of evidence relevant to this level: "Description of the presented hierarchy level."
          Additional evidence from previous level: "Description of the presented hierarchy level."
          Key Words/Phrases: "Validation hierarchy"
      Level 2: 
        Code: 2
        Name: Level 2
        Descriptors: 
          Descriptor: "More than one level (i.e. level refers to either material level, component level, subsystem level, etc.) of an incomplete validation hierarchy is defined (etc.). "
          Additional Info: "Incomplete hierarchy can be specified by a PIRT but a validation plan is desired."
          Change(s) from previous level: "Main differences between Level 1 and 2: 
1) More than one validation hierarchy level is required "
          Brief description of evidence relevant to this level: "Description of the presented hierarchy levels."
          Additional evidence from previous level: "Description of additional validation hierarchy level. "
          Key Words/Phrases: "Validation hierarchy"
      Level 3: 
        Code: 3
        Name: Level 3
        Descriptors: 
          Descriptor: "Complete validation hierarchy is defined. "
          Additional Info: "A complete validation hierarchy must be defined by a validation plan. A PIRT alone is insufficient to respond to this level. "
          Change(s) from previous level: "Main differences between Level 2 and 3: 
1) Complete validation hierarchy defined."
          Brief description of evidence relevant to this level: "Description of the complete validation hierarchy. "
          Additional evidence from previous level: "Completion of the validation hierarchy description."
          Key Words/Phrases: "All levels"
    Subelements: 
  UQ: 
    Name: Uncertainty Quantification
    Abbreviation: UQ
    Color: 0,173,208
    Levels: 
      Level 0: 
        Code: 0
        Name: Level 0
        Descriptors: 
          Descriptor: "No uncertainties identified/characterized"
          Additional Info: "Aleatory = stochastic uncertainty; \"Epistemic\" = incomplete knowledge uncertainty; \"characterized\" = broader term than \"quantified\" but default to \"quantified\" if in doubt. See Sandia QMU documentation for presentation of aleatory and epistemic uncertainty logic. The key  implication is that characterization of aleatory uncertainty is technically different than that for epistemic uncertainty."
          Change(s) from previous level: "n/a"
          Brief description of evidence relevant to this level: "None"
          Additional evidence from previous level: "n/a"
          Key Words/Phrases: "Aleatory; epistemic; characterized"
      Level 1: 
        Code: 1
        Name: Level 1
        Descriptors: 
          Descriptor: "Some uncertainties identified/characterized. Aleatory/epistemic separation (segregation, etc.) not performed. "
          Additional Info: "Separation - the aleatory uncertainties are separately identified/characterized from epistemic uncertainties. No evidence of completeness of uncertainty ID/characterization is required."
          Change(s) from previous level: "Main differences between Level 0 and 1: 
1) Uncertainty identification/characterization is performed and reported"
          Brief description of evidence relevant to this level: "Documentation of uncertainty identification/characterization"
          Additional evidence from previous level: "Documentation of uncertainty identification/characterization"
          Key Words/Phrases: "Separation (segregation)"
      Level 2: 
        Code: 2
        Name: Level 2
        Descriptors: 
          Descriptor: "Some uncertainties identified/characterized. Aleatory/epistemic separation (segregation, etc.) is performed for these uncertainties."
          Additional Info: ""
          Change(s) from previous level: "Main differences between Level 1 and 2: 
1) Uncertainty identification/characterization is performed and reported
2)Aleatory/epistemic separation is performed and reported"
          Brief description of evidence relevant to this level: "Documentation of uncertainty identification/characterization. Documentation of aleatory/epistemic separation."
          Additional evidence from previous level: "Documentation of aleatory/epistemic separation."
          Key Words/Phrases: ""
      Level 3: 
        Code: 3
        Name: Level 3
        Descriptors: 
          Descriptor: "All significant uncertainties identified/characterized except for unknown/unknowns. Aleatory/epistemic separation (segregation, etc.) is performed for these uncertainties."
          Additional Info: "Unknown unknown - uncertainties that we can't identify."
          Change(s) from previous level: "Main differences between Level 2 and 3: 
1) ALL uncertainties rather than SOME uncertainties
2) Logic around \"all\" uncertainties characterized"
          Brief description of evidence relevant to this level: "Documentation of uncertainty identification/characterization. Documentation of aleatory/epistemic separation. Documentation of logic around \"all\" uncertainties characterize"
          Additional evidence from previous level: "Documentation of logic around \"all\" uncertainties characterize"
          Key Words/Phrases: "unknown unknown"
    Subelements: 
Planning:
  Planning Fields:
    Summary:
      required: Optional
      type: RichText
    Notes/Assumptions:
      required: Optional
      type: RichText
    Action Items:
      required: Optional
      type: Action Item Table
  Planning Types:
    Action Item Table:
      Identifier:
        required: Optional
        type: Text
      Description:
        required: Optional
        type: Text
      Status:
        required: Optional
        type: Select
        values:
          - Open
          - In Progress
          - Resolved
          - Canceled
      Status Narrative:
        required: Optional
        type: RichText
      Priority:
        required: Optional
        type: Select
        values:
          - High
          - Medium
          - Low
      Owner:
        required: Optional
        type: Text
      Created Date:
        required: Optional
        type: Date
      Planned Completion Date:
        required: Optional
        type: Date
      Actual Completion Date:
        required: Optional
        type: Date
  Planning Questions:
    RGF:
      - "Has the model been de-featured and to what extent are the primary and secondary features included (ex. Fillets, bolts, holes, cables, etc)?"
      - "For which major features has the sensitivity been quantified (few, some, all)?"
    PMMF:
      - "To what extent do the phenomena covered in the PIRT align with the major physics that are included in the application model, and are the same capabilities that were assessed in the PIRT applicableimulation been rigorously checked (by the analyst, by other analysts, by multiple other users, peer review panel (external or internal))?"
      - "How were the existing validation comparisons conducted (quantitative vs. qualitative), and how was experimental uncertainty/error in the test data incorporated?"
      - "Which individual phenomena have specific validation comparisons?"
      - "To what extent does the application domain intersect the validation domain for this physics and material model (does not intersect, partially intersects, entirely contained)?"
    CVER:
      - "Is the code capability managed to identified SQE practices? If so, reference them."
      - "What regression tests and verification test suite (VERTS) are available for the code capabilities?"
      - "How is the SQE process managed and optimized?"
    SVER:
      - "How have numerical errors incurred from spatial, temporal, and stochastic resolution been accounted for (qualitative vs. quantitative)?"
      - "How and by whom has the accuracy of the input decks for the simulation been checked (by the analyst, by other analysts, by multiple other users)?"
      - "How are these errors expected to impact all of the relevant QoIs?"
      - "How and by whom has the accuracy of the inputs to the post-processing tools been checked (by the analyst, by other analysts, by multiple other users)?"
      - "Have these activities been subjected to peer review (by the team, internal, external), and where are these results documented?"
      - "Is a common set of post-processing tools used for the analysis, and are they held to a common set of SQE standards?"
    VAL:
      - "Has a validation hierarchy been defined (i.e., mapping from material to component to subsystem to full system levels)?"
      - "Have the steps in this methodology been performed (i.e., have quantitative comparisons been made at different levels of the hierarchy)?"
    UQ:
      - "Has an inventory of uncertainty sources been taken, and have they been classified according to these forms?"
      - "How have the most important uncertainty sources for the relevant QoIs been identified (e.g., SME judgment, local sensitivity analysis, global sensitivity analysis, etc.)?"
      - "What is the source of information (e.g., legacy, literature, direct measurement, calibration, etc.) that is used for uncertainty characterization (e.g., classification as aleatory vs. epistemic, uncertainty representation, distributional assumptions, etc.)?"
